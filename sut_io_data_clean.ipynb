{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e19e2409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1720820f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_excel_data(file_path, output_path=None):\n",
    "    \"\"\"\n",
    "    Clean Excel data with multi-row headers starting from row 4.\n",
    "    Handles merged cells and preserves comma-separated header names.\n",
    "    \n",
    "    Parameters:\n",
    "    file_path (str): Path to the input Excel file\n",
    "    output_path (str): Path for the output file (optional)\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Cleaned dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "    last_sheet = xls.sheet_names[-1]\n",
    "    print(\"✅ Loading last sheet:\", last_sheet)\n",
    "\n",
    "    df_raw = pd.read_excel(file_path, sheet_name=last_sheet, header=None, dtype=str)\n",
    "    \n",
    "    # Extract row 3 and row 4 (indices 2 and 3)\n",
    "    header_row_1 = df_raw.iloc[2].fillna('')\n",
    "    header_row_2 = df_raw.iloc[3].fillna('')\n",
    "    \n",
    "    # Combine headers: If row 4 has content, use it; otherwise use row 3\n",
    "    # For merged cells, we'll concatenate with a space\n",
    "    combined_headers = []\n",
    "    \n",
    "    for col_idx in range(len(header_row_1)):\n",
    "        h1 = str(header_row_1.iloc[col_idx]).strip()\n",
    "        h2 = str(header_row_2.iloc[col_idx]).strip()\n",
    "        \n",
    "        # Remove 'nan' strings that might appear\n",
    "        h1 = '' if h1 == 'nan' else h1\n",
    "        h2 = '' if h2 == 'nan' else h2\n",
    "        \n",
    "        # Combine headers intelligently\n",
    "        if h1 and h2:\n",
    "            # Both rows have content\n",
    "            combined = f\"{h1} - {h2}\"\n",
    "        elif h1:\n",
    "            # Only row 3 has content\n",
    "            combined = h1\n",
    "        elif h2:\n",
    "            # Only row 4 has content\n",
    "            combined = h2\n",
    "        else:\n",
    "            # Neither has content, use column letter\n",
    "            combined = f\"Column_{col_idx}\"\n",
    "        \n",
    "        combined_headers.append(combined)\n",
    "    \n",
    "    # Get the data starting from row 5 (index 4)\n",
    "    df_clean = df_raw.iloc[4:].copy()\n",
    "    \n",
    "    # Set the combined headers\n",
    "    df_clean.columns = combined_headers\n",
    "    \n",
    "    # Reset index\n",
    "    df_clean.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Remove completely empty rows\n",
    "    df_clean = df_clean.dropna(how='all')\n",
    "    \n",
    "    # Remove completely empty columns\n",
    "    df_clean = df_clean.dropna(axis=1, how='all')\n",
    "    \n",
    "    # Clean up any remaining issues\n",
    "    df_clean = df_clean.replace('nan', np.nan)\n",
    "    \n",
    "    # Save to output file if specified\n",
    "    if output_path:\n",
    "        df_clean.to_csv(output_path, index=False)\n",
    "        print(f\"Cleaned data saved to: {output_path}\")\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "90fd1f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_headers(file_path, output_path):\n",
    "    \"\"\"\n",
    "    Preview the first few rows including headers to verify structure.\n",
    "    \n",
    "    Parameters:\n",
    "    file_path (str): Path to the Excel file\n",
    "    num_rows (int): Number of data rows to preview\n",
    "    \"\"\"\n",
    "    df_raw = pd.read_excel(file_path, sheet_name=-1, header=None)\n",
    "    \n",
    "    # Clean and show result\n",
    "    df_clean = clean_excel_data(file_path, output_path)\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e4816fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loading last sheet: 6.6\n",
      "Cleaned data saved to: cleaned_data/sut_io_cleaned_data.csv\n"
     ]
    }
   ],
   "source": [
    "input_file = \"data/SUT and IO By Divisions -En.xlsx\"    \n",
    "output_file = \"cleaned_data/sut_io_cleaned_data.csv\"\n",
    "\n",
    "# Preview the data\n",
    "df = preview_headers(input_file, output_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
